{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic text recognition using MDLSTM + CTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMStateTuple\n",
    "from tensorflow.contrib.rnn.python.ops.core_rnn_cell import _linear\n",
    "from tensorflow.python.ops.rnn import dynamic_rnn\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration.\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.DEBUG,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "# Model path.\n",
    "MODEL_PATH = \"./models/model.ckpt\"\n",
    "\n",
    "# Summary directory.\n",
    "SUMMARY_PATH = \"./logs/\"\n",
    "\n",
    "\n",
    "# Constants.\n",
    "SPACE_TOKEN = 'sp'\n",
    "SPACE_INDEX = 63\n",
    "FIRST_INDEX = 0 \n",
    "\n",
    "# Number of features.\n",
    "NUM_FEATURES = 2200\n",
    "\n",
    "# Accounting to the symbol dictionary defined above\n",
    "NUM_CLASSES = 66\n",
    "\n",
    "# Hyper-parameters.\n",
    "NUM_EPOCHS = 1\n",
    "NUM_HIDDEN = 10\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Optimizer parameters.\n",
    "INITIAL_LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "WIND_H = 5\n",
    "WIND_W = 5\n",
    "\n",
    "PARL_EXC = 1000\n",
    "\n",
    "H  = 150\n",
    "W  =2200\n",
    "CH =   1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "symbol_dict = {'hh': 1,'am':2,'ae': 3,'ah': 4,'aa': 5,'ba': 6,\n",
    "               'ta': 7,'teE': 8,'th': 9,'ja': 10,'ha': 11,'kh': 12,\n",
    "               'da': 13,'dh': 14,'ra': 15,'za': 16,'se': 17,'sh': 18,\n",
    "               'sa': 19,'de': 20,'to': 21,'zha': 22,'ay': 23,'gh': 24,\n",
    "               'fa': 25,'ka': 26,'ke': 27,'la': 28,'ma': 29,'na': 30,\n",
    "               'he': 31,'wa': 32,'wl': 33,'ya': 34,'ee': 35,'al': 36,\n",
    "               'n0': 37,'n1': 38,'n2': 39,'n3': 40,'n4': 41,'n5': 42,\n",
    "               'n6': 43,'n7': 44,'n8': 45,'n9': 46,'atr': 47,'col': 48,\n",
    "               'dbq': 49,'com': 50,'qts': 51,'exc': 52,'dot': 53,'bro': 54,\n",
    "               'brc': 55,'fsl': 56,'bsl': 57,'equ': 58,'hyp': 59,'usc': 60,\n",
    "               'src': 61,'per': 62, 'sp': 63, 'te': 64\n",
    "              }\n",
    "def to_symbols(seq):\n",
    "    new_seq = []\n",
    "    for c in seq:\n",
    "        new_seq.append(symbol_dict[c])\n",
    "    return new_seq\n",
    "def load_data(image_folder_location, txt_file_location):\n",
    "    \"\"\"\n",
    "        Loads data from the KHATT dataset, images are assumed to be text line images, and the ground truth table is assumed to be stored in a .txt file\n",
    "    \"\"\"\n",
    "    \n",
    "    txt_file = open(txt_file_location, \"r\")\n",
    "    lines = txt_file.readlines()\n",
    "    list_dir = os.listdir(image_folder_location)\n",
    "    list_data = []\n",
    "    list_labels = []\n",
    "    #dict_data = {}\n",
    "    for i in range(len(list_dir)):\n",
    "        im = Image.open(image_folder_location + \"/\"+list_dir[i])\n",
    "        imarray = np.array(im)\n",
    "        \n",
    "        aspect = imarray.shape[1]/imarray.shape[0]\n",
    "        if aspect < 5:\n",
    "            continue\n",
    "            \n",
    "        im = im.resize((2200, 150), Image.ANTIALIAS)\n",
    "        imarray = np.array(im)\n",
    "        \n",
    "        list_data.append(imarray.reshape(150,2200,1))\n",
    "        line_data = lines[i].replace(list_dir[i],\"\").replace(\"\t \",\"\")\n",
    "        list_labels.append(to_symbols(line_data.split()))\n",
    "        #dict_data[list_data[i]] = line_data\n",
    "    return list_data,list_labels\n",
    "x_train, y_train = load_data(\"C:/Users/Yazeed/Desktop/KHATT/Training\",\"C:/Users/Yazeed/Desktop/KHATT/Training-Groundtruth.txt\")\n",
    "x_test, y_test = load_data(\"C:/Users/Yazeed/Desktop/KHATT/Test\",\"C:/Users/Yazeed/Desktop/KHATT/Test-Groundtruth.txt\")\n",
    "\"\"\"summ = np.sum((np.array(x_train[i])).shape[0] for i in range(len(x_train)))\n",
    "print(summ/len(x_train))\n",
    "summ = np.sum((np.array(x_train[i])).shape[1] for i in range(len(x_train)))\n",
    "print(summ/len(x_train))\"\"\"\n",
    "print(\"Training set:\", len(x_train), len(y_train))\n",
    "print(\"Testing set:\", len(x_test), len(y_test))\n",
    "plt.imshow(x_train[random.randint(0,len(x_train))].reshape(150,2200))\n",
    "plt.imshow(x_test[random.randint(0,len(x_test))].reshape(150,2200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Edit Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(targ, hyp):\n",
    "    \"\"\"\n",
    "        Calculates the number of changes required to turn a hypothesis string to a target (reference string)\n",
    "    \"\"\"\n",
    "    n = len(targ)\n",
    "    m = len(hyp)\n",
    "    \n",
    "    ins  = 0\n",
    "    dels = 0\n",
    "    subs = 0\n",
    "    corr = 0\n",
    "    \n",
    "    D = np.zeros((n+1,m+1))\n",
    "    \n",
    "    D[:,0] = np.arange(n+1)\n",
    "    D[0,:] = np.arange(m+1)\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if targ[i-1] == hyp[j-1]:\n",
    "                D[i, j] = D[i-1, j-1]\n",
    "            else:\n",
    "                D[i, j] = min(D[i-1, j],D[i, j-1],D[i-1, j-1])+1\n",
    "    \n",
    "    i = n\n",
    "    j = m\n",
    "    while i>0 and j>0:\n",
    "        if targ[i-1] == hyp[j-1]:\n",
    "            corr += 1\n",
    "        elif D[i-1, j] == D[i, j]-1:\n",
    "            ins += 1\n",
    "            j += 1\n",
    "        elif D[i, j-1] == D[i, j]-1:\n",
    "            dels += 1\n",
    "            i += 1\n",
    "        elif D[i-1, j-1] == D[i, j]-1:\n",
    "            subs += 1\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "    ins += i\n",
    "    dels += j\n",
    "    \n",
    "    return D[-1, -1],ins,dels,subs,corr\n",
    "i,j,k,l,m = edit_distance(\"human\",\"humen\")\n",
    "print(int(i),j,k,l,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectionist Temporal Classification (CTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss(params, seq, blank=0, is_prob=True):\n",
    "    \"\"\"\n",
    "        CTC loss funtion. \n",
    "\n",
    "        Description: \n",
    "        takes a sequence of characters, calculates best path, calculates the network gradients according to the path and the prdedcitons.\n",
    "\n",
    "        Input:\n",
    "        params ~ nxm matrix of n probability distributions over m frames.\n",
    "        seq ~ sequence of character id's.\n",
    "        is_prob ~ are the params normalized? (already passed through softmax)\n",
    "\n",
    "        Output:\n",
    "        objective\n",
    "        gradient\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(params)\n",
    "    try:\n",
    "        seqLen = seq.shape[0]      # length of sequence\n",
    "        numchars = params.shape[0] # num of labels\n",
    "        L = 2*seqLen + 1           # length of label sequence with blanks\n",
    "        T = params.shape[1]        # lenght of time (utterance)\n",
    "\n",
    "        alphas = np.zeros((L, T))\n",
    "        betas  = np.zeros((L, T))\n",
    "\n",
    "        if not is_prob:\n",
    "            params = params - np.max(params, axis=0)\n",
    "            params = np.exp(params)\n",
    "            params = params / np.sum(params, axis=0)\n",
    "\n",
    "        # initialize the alphas and forward pass\n",
    "        #print (params.shape)\n",
    "        alphas[0,0] = params[blank, 0]\n",
    "        alphas[1,0] = params[seq[0],0]\n",
    "        c = np.sum(alphas[:,0])\n",
    "        alphas[:,0]=alphas[:,0] / c\n",
    "        forward = np.log(c)\n",
    "\n",
    "        for t in range(1,T):\n",
    "            start = max(0,L-2*(T-t))\n",
    "            end = min(2*t+2,L)\n",
    "\n",
    "            for s in range(start, L):\n",
    "                l = (s-1)/2\n",
    "                # blank\n",
    "                if s%2 == 0:\n",
    "                    if s==0:\n",
    "                        alphas[s, t] = alphas[s, t-1] * params[blank, t]\n",
    "                    else:\n",
    "                        alphas[s, t] = (alphas[s, t-1] + alphas[s-1, t-1]) * params[blank, t]\n",
    "                # same label twice\n",
    "                elif s == 1 or seq[l] == seq[l-1]:\n",
    "                    alphas[s, t] = (alphas[s, t-1] + alphas[s-1, t-1])* params[seq[l], t]\n",
    "                else:\n",
    "                    alphas[s, t] = (alphas[s, t-1] + alphas[s-1, t-1] + alphas[s-2, t-1])* params[seq[l], t]\n",
    "            # normalize at current time (prevent underflow)\n",
    "            c = np.sum(alphas[start:end], t)\n",
    "            alphas[start:end,t] = alphas[start:end,t] / c\n",
    "            forward += np.log(c)\n",
    "\n",
    "        # initialize the betas and backwards pass\n",
    "        betas[-1, -1] = params[blank, -1]\n",
    "        betas[-2, -1] = params[seq[-1], -1]\n",
    "        c = np.sum(betas[:,-1])\n",
    "        betas[:, -1]  = betas[:, -1] / c\n",
    "        backward = np.log(c)\n",
    "        for t in range(T-2,-1,-1):\n",
    "            start = max(0,L-2*(T-t))\n",
    "            end = min(2*t+2,L)\n",
    "\n",
    "            for s in range(end-1, -1, -1):\n",
    "                l = (s-1)/2\n",
    "                # blank\n",
    "                if s%2 == 0:\n",
    "                    if s==L-1:\n",
    "                        betas[s, t] = betas[s, t+1] * params[blank, t]\n",
    "                    else:\n",
    "                        betas[s, t] = (betas[s, t+1] + betas[s+1, t+1]) * params[blank, t]\n",
    "                # same label twice\n",
    "                elif s == L-2 or seq[l] == seq[l+1]:\n",
    "                    betas[s, t] = (betas[s, t+1] + alphas[s+1, t+1])* params[seq[l], t]\n",
    "                else:\n",
    "                    alphas[s, t] = (alphas[s, t+1] + alphas[s+1, t+1] + alphas[s+2, t+1])* params[seq[l], t]\n",
    "            # normalize at current time (prevent underflow)\n",
    "            c = np.sum(betas[start:end], t)\n",
    "            betas[start:end,t] = betas[start:end,t] / c\n",
    "            backward += np.log(c)\n",
    "\n",
    "        # compute gradient with respect to unnormalized input parameters\n",
    "        grad = np.zeros(params.shape)\n",
    "        ab = alphas*betas\n",
    "\n",
    "        for s in range(L):\n",
    "            # blank\n",
    "            if s%2 == 0:\n",
    "                grad[blank, :] += ab[s, :]\n",
    "                ab[s, :] = ab[s, :] / params[blank, :]\n",
    "            else:\n",
    "                grad[seq[(s-1)/2], :] += ab[s, :]\n",
    "                ab[s, :] = ab[s, :] / (params[seq[(s-1)/2, :]])\n",
    "        absum = np.sum(ab, axis=0)\n",
    "\n",
    "        grad = params - grad / (params * absum)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        return -forward, grad, True\n",
    "    return -forward, grad, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimentional Long Short-Term Memory (MDLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln(tensor, scope=None, epsilon=1e-5):\n",
    "    \"\"\" \n",
    "        Layer normalizes a 2D tensor along its second axis \n",
    "    \"\"\"\n",
    "    assert (len(tensor.get_shape()) == 2)\n",
    "    m, v = tf.nn.moments(tensor, [1], keep_dims=True)\n",
    "    if not isinstance(scope, str):\n",
    "        scope = ''\n",
    "    with tf.variable_scope(scope + 'layer_norm'):\n",
    "        scale = tf.get_variable('scale',\n",
    "                                shape=[tensor.get_shape()[1]],\n",
    "                                initializer=tf.constant_initializer(1))\n",
    "        shift = tf.get_variable('shift',\n",
    "                                shape=[tensor.get_shape()[1]],\n",
    "                                initializer=tf.constant_initializer(0))\n",
    "    ln_initial = (tensor - m) / tf.sqrt(v + epsilon)\n",
    "\n",
    "    return ln_initial * scale + shift\n",
    "\n",
    "\n",
    "class MultiDimensionalLSTMCell(RNNCell):\n",
    "    \"\"\"\n",
    "        Adapted from TF's BasicLSTMCell to use Layer Normalization.\n",
    "        Note that state_is_tuple is always True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_units, forget_bias=0.0, activation=tf.nn.tanh):\n",
    "        self._num_units = num_units\n",
    "        self._forget_bias = forget_bias\n",
    "        self._activation = activation\n",
    "\n",
    "    def state_size(self):\n",
    "        return LSTMStateTuple(self._num_units, self._num_units)\n",
    "\n",
    "    def output_size(self):\n",
    "        return self._num_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \"\"\"\n",
    "            Long short-term memory cell (LSTM).\n",
    "            inputs (batch,n)\n",
    "            state: the states and hidden unit of the two cells\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(scope or type(self).__name__,reuse = tf.AUTO_REUSE):\n",
    "            c1, c2, h1, h2 = state\n",
    "\n",
    "            # change bias argument to False since LN will add bias via shift\n",
    "            concat = _linear([inputs, h1, h2], 5 * self._num_units, False)\n",
    "\n",
    "            i, j, f1, f2, o = tf.split(value=concat, num_or_size_splits=5, axis=1)\n",
    "\n",
    "            # add layer normalization to each gate\n",
    "            i = ln(i, scope='i/')\n",
    "            j = ln(j, scope='j/')\n",
    "            f1 = ln(f1, scope='f1/')\n",
    "            f2 = ln(f2, scope='f2/')\n",
    "            o = ln(o, scope='o/')\n",
    "\n",
    "            new_c = (c1 * tf.nn.sigmoid(f1 + self._forget_bias) +\n",
    "                     c2 * tf.nn.sigmoid(f2 + self._forget_bias) + tf.nn.sigmoid(i) *\n",
    "                     self._activation(j))\n",
    "\n",
    "            # add layer_normalization in calculation of new hidden state\n",
    "            new_h = self._activation(ln(new_c, scope='new_h/')) * tf.nn.sigmoid(o)\n",
    "            new_state = LSTMStateTuple(new_c, new_h)\n",
    "\n",
    "            return new_h, new_state\n",
    "\n",
    "\n",
    "def multi_dimensional_rnn_while_loop(rnn_size, input_data, sh, dims=None, scope_n=\"layer1\"):\n",
    "    \"\"\"\n",
    "        Implements naive multi dimension recurrent neural networks\n",
    "\n",
    "        rnn_size: the hidden units\n",
    "        input_data: the data to process of shape [batch,h,w,channels]\n",
    "        sh: [height,width] of the windows\n",
    "        dims: dimensions to reverse the input data,eg.\n",
    "            dims=[False,True,True,False] => true means reverse dimension\n",
    "        scope_n : the scope\n",
    "\n",
    "        returns [batch,h/sh[0],w/sh[1],rnn_size] the output of the lstm\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(\"MultiDimensionalLSTMCell-\" + scope_n):\n",
    "\n",
    "        # Create multidimensional cell with selected size\n",
    "        cell = MultiDimensionalLSTMCell(rnn_size)\n",
    "\n",
    "        # Get the shape of the input (batch_size, x, y, channels)\n",
    "        batch_size, X_dim, Y_dim, channels = input_data.shape.as_list()\n",
    "        # Window size\n",
    "        X_win, Y_win = sh\n",
    "        # Get the runtime batch size\n",
    "        batch_size_runtime = tf.shape(input_data)[0]\n",
    "\n",
    "        # If the input cannot be exactly sampled by the window, we patch it with zeros\n",
    "        if X_dim % X_win != 0:\n",
    "            # Get offset size\n",
    "            offset = tf.zeros([batch_size_runtime, X_win - (X_dim % X_win), Y_dim, channels])\n",
    "            # Concatenate X dimension\n",
    "            input_data = tf.concat(axis=1, values=[input_data, offset])\n",
    "            # Update shape value\n",
    "            X_dim = input_data.shape[1].value\n",
    "\n",
    "        # The same but for Y axis\n",
    "        if Y_dim % Y_win != 0:\n",
    "            # Get offset size\n",
    "            offset = tf.zeros([batch_size_runtime, X_dim, Y_win - (Y_dim % Y_win), channels])\n",
    "            # Concatenate Y dimension\n",
    "            input_data = tf.concat(axis=2, values=[input_data, offset])\n",
    "            # Update shape value\n",
    "            Y_dim = input_data.shape[2].value\n",
    "\n",
    "        # Get the steps to perform in X and Y axis\n",
    "        h, w = int(X_dim / X_win), int(Y_dim / Y_win)\n",
    "\n",
    "        # Get the number of features (total number of input values per step)\n",
    "        features = Y_win * X_win * channels\n",
    "\n",
    "        # Reshape input data to a tensor containing the step indexes and features inputs\n",
    "        # The batch size is inferred from the tensor size\n",
    "        x = tf.reshape(input_data, [batch_size_runtime, h, w, features])\n",
    "\n",
    "        # Reverse the selected dimensions\n",
    "        if dims is not None:\n",
    "            assert dims[0] is False and dims[3] is False\n",
    "            x = tf.reverse(x, dims)\n",
    "\n",
    "        # Reorder inputs to (h, w, batch_size, features)\n",
    "        x = tf.transpose(x, [1, 2, 0, 3])\n",
    "        # Reshape to a one dimensional tensor of (h*w*batch_size , features)\n",
    "        x = tf.reshape(x, [-1, features])\n",
    "        # Split tensor into h*w tensors of size (batch_size , features)\n",
    "        x = tf.split(axis=0, num_or_size_splits=h * w, value=x)\n",
    "\n",
    "        # Create an input tensor array (literally an array of tensors) to use inside the loop\n",
    "        inputs_ta = tf.TensorArray(dtype=tf.float32, size=h * w, name='input_ta')\n",
    "        # Unstack the input X in the tensor array\n",
    "        inputs_ta = inputs_ta.unstack(x)\n",
    "        # Create an input tensor array for the states\n",
    "        states_ta = tf.TensorArray(dtype=tf.float32, size=h * w + 1, name='state_ta', clear_after_read=False)\n",
    "        # And an other for the output\n",
    "        outputs_ta = tf.TensorArray(dtype=tf.float32, size=h * w, name='output_ta')\n",
    "\n",
    "        # initial cell hidden states\n",
    "        # Write to the last position of the array, the LSTMStateTuple filled with zeros\n",
    "        states_ta = states_ta.write(h * w, LSTMStateTuple(tf.zeros([batch_size_runtime, rnn_size], tf.float32),\n",
    "                                                          tf.zeros([batch_size_runtime, rnn_size], tf.float32)))\n",
    "\n",
    "        # Function to get the sample skipping one row\n",
    "        def get_up(t_, w_):\n",
    "            return t_ - tf.constant(w_)\n",
    "\n",
    "        # Function to get the previous sample\n",
    "        def get_last(t_, w_):\n",
    "            return t_ - tf.constant(1)\n",
    "\n",
    "        # Controls the initial index\n",
    "        time = tf.constant(0)\n",
    "        zero = tf.constant(0)\n",
    "\n",
    "        # Body of the while loop operation that applies the MD LSTM\n",
    "        def body(time_, outputs_ta_, states_ta_):\n",
    "\n",
    "            # If the current position is less or equal than the width, we are in the first row\n",
    "            # and we need to read the zero state we added in row (h*w). \n",
    "            # If not, get the sample located at a width distance.\n",
    "            state_up = tf.cond(tf.less_equal(time_, tf.constant(w)),\n",
    "                               lambda: states_ta_.read(h * w),\n",
    "                               lambda: states_ta_.read(get_up(time_, w)))\n",
    "\n",
    "            # If it is the first step we read the zero state if not we read the immediate last\n",
    "            state_last = tf.cond(tf.less(zero, tf.mod(time_, tf.constant(w))),\n",
    "                                 lambda: states_ta_.read(get_last(time_, w)),\n",
    "                                 lambda: states_ta_.read(h * w))\n",
    "\n",
    "            # We build the input state in both dimensions\n",
    "            current_state = state_up[0], state_last[0], state_up[1], state_last[1]\n",
    "            # Now we calculate the output state and the cell output\n",
    "            out, state = cell(inputs_ta.read(time_), current_state,)\n",
    "            # We write the output to the output tensor array\n",
    "            outputs_ta_ = outputs_ta_.write(time_, out)\n",
    "            # And save the output state to the state tensor array\n",
    "            states_ta_ = states_ta_.write(time_, state)\n",
    "\n",
    "            # Return outputs and incremented time step \n",
    "            return time_ + 1, outputs_ta_, states_ta_\n",
    "\n",
    "        # Loop output condition. The index, given by the time, should be less than the\n",
    "        # total number of steps defined within the image\n",
    "        def condition(time_, outputs_ta_, states_ta_):\n",
    "            return tf.less(time_, tf.constant(h * w))\n",
    "\n",
    "        # Run the looped operation\n",
    "        result, outputs_ta, states_ta = tf.while_loop(condition, body, [time, outputs_ta, states_ta],\n",
    "                                                      parallel_iterations=PARL_EXC)\n",
    "\n",
    "        # Extract the output tensors from the processesed tensor array\n",
    "        outputs = outputs_ta.stack()\n",
    "        states = states_ta.stack()\n",
    "        #print(outputs.shape)\n",
    "        # Reshape outputs to match the shape of the input\n",
    "        y = tf.reshape(outputs, [h, w, batch_size_runtime, rnn_size])\n",
    "        #print(\"y: \",y.shape)\n",
    "        # Reorder te dimensions to match the input\n",
    "        y = tf.transpose(y, [2, 0, 1, 3])\n",
    "        # Reverse if selected\n",
    "        if dims is not None:\n",
    "            y = tf.reverse(y, dims)\n",
    "        #print(\"y's final shape: \", y.shape)\n",
    "        # Return the output and the inner states\n",
    "        return y, states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 0\n",
    "def next_batch(batch_size):\n",
    "    start = current*batch_size\n",
    "    end = len(x_train)\n",
    "    if((current+1)*batch_size<end):\n",
    "        end = (current+1)*batch_size\n",
    "    else:\n",
    "        current = -1\n",
    "    current += 1\n",
    "    return x_train[start:end],y_train[start:end]\n",
    "def get_sequence_lengths(inputs):\n",
    "    \"\"\"\n",
    "    Get sequence length of each sequence.\n",
    "    Args:\n",
    "        inputs: list of lists where each element is a sequence.\n",
    "    Returns:\n",
    "        array of sequence lengths.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for input in inputs:\n",
    "        result.append(len(input))\n",
    "\n",
    "    return np.array(result, dtype=np.int64)\n",
    "\n",
    "def texts_encoder(texts, first_index=(ord('a') - 1), space_index=0, space_token='<space>'):\n",
    "    \"\"\"\n",
    "    Encode texts to numbers.\n",
    "    Args:\n",
    "        texts: list of texts.\n",
    "            Data directory.\n",
    "        first_index: int.\n",
    "            First index (usually index of 'a').\n",
    "        space_index: int.\n",
    "            Index of 'space'.\n",
    "        space_token: string.\n",
    "            'space' representation.\n",
    "    Returns:\n",
    "        array of encoded texts.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for text in texts:\n",
    "        item = make_char_array(text, space_token)\n",
    "        item = np.asarray([space_index if x == space_token else ord(x) - first_index for x in item])\n",
    "        result.append(item)\n",
    "\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def sequence_decoder(sequence, first_index=(ord('a') - 1)):\n",
    "    \"\"\"\n",
    "    Read text files.\n",
    "    Args:\n",
    "        sequence: list of int.\n",
    "            Encoded sequence\n",
    "        first_index: int.\n",
    "            First index (usually index of 'a').\n",
    "    Returns:\n",
    "        decoded_text: string.\n",
    "    \"\"\"\n",
    "    decoded_text = ''.join([chr(x) for x in np.asarray(sequence) + first_index])\n",
    "    # Replacing blank label to none.\n",
    "    decoded_text = decoded_text.replace(chr(ord('z') + 1), '')\n",
    "    # Replacing space label to space.\n",
    "    decoded_text = decoded_text.replace(chr(ord('a') - 1), ' ')\n",
    "    return decoded_text\n",
    "def sparse_tuples_from_sequences(sequences, dtype=np.int32):\n",
    "    \"\"\"\n",
    "    Create a sparse representations of inputs.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indexes = []\n",
    "    values = []\n",
    "\n",
    "    for n, sequence in enumerate(sequences):\n",
    "        #print([n]*len(sequence),range(len(sequence)))\n",
    "        indexes.extend(zip([n] * len(sequence), range(len(sequence))))\n",
    "        values.extend(sequence)\n",
    "\n",
    "    indexes = np.asarray(indexes, dtype=np.int64)\n",
    "    #print(values)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indexes).max(0)[1] + 1], dtype=np.int64)\n",
    "\n",
    "    return indexes, values, shape\n",
    "\n",
    "\n",
    "def make_char_array(text, space_token='<space>'):\n",
    "    \"\"\"\n",
    "    Make text as char array. Replace spaces with space token.\n",
    "    Args:\n",
    "        text: string.\n",
    "            Given text.\n",
    "        space_token: string.\n",
    "            Text which represents space char.\n",
    "    Returns:\n",
    "        string array.\n",
    "            Split text.\n",
    "    \"\"\"\n",
    "    result = np.hstack([space_token if x == ' ' else list(x) for x in text])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training data.\n",
    "train_inputs = np.array(x_train)\n",
    "train_labels = np.asarray(y_train)\n",
    "\n",
    "# Validation data.\n",
    "validation_inputs = np.array(x_test)\n",
    "validation_labels = np.asarray(y_test)\n",
    "validation_labels = sparse_tuples_from_sequences(validation_labels)\n",
    "\n",
    "# Testing data.\n",
    "test_inputs = np.array(x_test)\n",
    "test_labels = np.asarray(y_test)\n",
    "test_labels = sparse_tuples_from_sequences(test_labels)\n",
    "test_texts = y_test\n",
    "\n",
    "#print(\"prepared\")\n",
    "train_sequence_lengths = get_sequence_lengths(train_inputs)\n",
    "validation_sequence_lengths = get_sequence_lengths(validation_inputs)\n",
    "test_sequence_lengths = get_sequence_lengths(test_inputs)\n",
    "with tf.device('/gpu:0'):\n",
    "    config = tf.ConfigProto()\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        #print(\"starting graph\")\n",
    "        logging.debug(\"Starting new TensorFlow graph.\")\n",
    "        inputs_placeholder = tf.placeholder(tf.float32, [None, H, W, CH])\n",
    "\n",
    "        # SparseTensor placeholder required by ctc_loss op.\n",
    "        labels_placeholder = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "        # 1d array of size [batch_size].\n",
    "        sequence_length_placeholder = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        # Defining the cell.\n",
    "        #def lstm_cell():\n",
    "        #    return tf.contrib.rnn.LSTMCell(NUM_HIDDEN, state_is_tuple=True)\n",
    "\n",
    "        # Stacking rnn cells.\n",
    "        #stack = tf.contrib.rnn.MultiRNNCell(\n",
    "        #    [lstm_cell() for _ in range(NUM_LAYERS)], state_is_tuple=True)\n",
    "\n",
    "        # Creates a recurrent neural network.\n",
    "        #outputs, _ = tf.nn.dynamic_rnn(stack, inputs_placeholder, sequence_length_placeholder, dtype=tf.float32)\n",
    "\n",
    "        shape = tf.shape(inputs_placeholder)\n",
    "        batch_size, max_time_steps = shape[0], shape[1]\n",
    "\n",
    "        # Reshaping to apply the same weights over the time steps.\n",
    "        #outputs = tf.reshape(outputs, [-1, NUM_HIDDEN])\n",
    "        rnn_out, _ = multi_dimensional_rnn_while_loop(rnn_size=NUM_HIDDEN, input_data=inputs_placeholder, sh=[WIND_H, WIND_W])\n",
    "        \"\"\"weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_CLASSES], stddev=0.1),\n",
    "                              name='weights')\n",
    "        bias = tf.Variable(tf.constant(0., shape=[NUM_CLASSES]),\n",
    "                           name='bias')\n",
    "\n",
    "        # Doing the affine projection.\n",
    "        print(outputs.shape, weights.shape)\n",
    "        logits = tf.matmul(outputs, weights) + bias\"\"\"\n",
    "        model_out = slim.fully_connected(inputs=rnn_out,\n",
    "                                num_outputs=66,\n",
    "                                activation_fn=None)\n",
    "        #print(model_out.shape)\n",
    "        logits = tf.reshape(model_out,[batch_size, -1, NUM_CLASSES])\n",
    "        #print(logits.shape)\n",
    "        #print(rnn_out.shape)\n",
    "        # Reshaping back to the original shape.\n",
    "        #logits = tf.reshape(logits, [batch_size, -1, NUM_CLASSES])\n",
    "\n",
    "        # Time is major.\n",
    "        logits = tf.transpose(logits, (1, 0, 2))\n",
    "        #print(\"defining loss\")\n",
    "        with tf.name_scope('loss'):\n",
    "            loss = tf.nn.ctc_loss(labels_placeholder, logits, sequence_length_placeholder)\n",
    "            cost = tf.reduce_mean(loss)\n",
    "            tf.summary.scalar(\"loss\", cost)\n",
    "        #print(\"defining optimizer\")\n",
    "        optimizer = tf.train.MomentumOptimizer(INITIAL_LEARNING_RATE, 0.9).minimize(cost)\n",
    "\n",
    "        # CTC decoder.\n",
    "        #print(\"decoder and label error rate\")\n",
    "        decoded, neg_sum_logits = tf.nn.ctc_greedy_decoder(logits, sequence_length_placeholder)\n",
    "\n",
    "        label_error_rate = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                                           labels_placeholder))\n",
    "    #print(\"starting session\")\n",
    "    with tf.Session(config=config, graph=graph) as session:\n",
    "        logging.debug(\"Starting TensorFlow session.\")\n",
    "\n",
    "        # Saver op to save and restore all the variables.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Merge all the summaries and write them out.\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "\n",
    "        # Initializing summary writer for TensorBoard.\n",
    "        summary_writer = tf.summary.FileWriter(SUMMARY_PATH, tf.get_default_graph())\n",
    "\n",
    "        # Initialize the weights and biases.\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        train_num = train_inputs.shape[0]\n",
    "        validation_num = validation_inputs.shape[0]\n",
    "\n",
    "        # Check if there is any example.\n",
    "        if train_num <= 0:\n",
    "            logging.error(\"There are no training examples.\")\n",
    "            pass\n",
    "\n",
    "        num_batches_per_epoch = math.ceil(train_num / BATCH_SIZE)\n",
    "        print(\"Starting training\")\n",
    "        for current_epoch in range(NUM_EPOCHS):\n",
    "            train_cost = 0\n",
    "            train_label_error_rate = 0\n",
    "            start_time = time.time()\n",
    "            print(\"Epoch:\"+str(current_epoch+1)+\"/\"+str(NUM_EPOCHS))\n",
    "            for step in range(num_batches_per_epoch):\n",
    "                # Format batches.\n",
    "                print(\"Batch: \"+str(step+1)+\"/\"+str(num_batches_per_epoch), end='\\r')\n",
    "                if int(train_num / ((step + 1) * BATCH_SIZE)) >= 1:\n",
    "                    indexes = [i % train_num for i in range(step * BATCH_SIZE, (step + 1) * BATCH_SIZE)]\n",
    "                else:\n",
    "                    indexes = [i % train_num for i in range(step * BATCH_SIZE, train_num)]\n",
    "                #print(\"batching...\")\n",
    "                #print(indexes)\n",
    "                batch_train_inputs = train_inputs[indexes]\n",
    "                batch_train_sequence_lengths = train_sequence_lengths[indexes]\n",
    "                batch_train_targets = sparse_tuples_from_sequences(train_labels[indexes])\n",
    "                #print(\"defining feed\")\n",
    "                feed = {inputs_placeholder: batch_train_inputs,\n",
    "                        labels_placeholder: batch_train_targets,\n",
    "                        sequence_length_placeholder: batch_train_sequence_lengths}\n",
    "                #print(\"calculating cost\")\n",
    "                batch_cost, _, summary = session.run([cost, optimizer, merged_summary], feed)\n",
    "                train_cost += batch_cost * BATCH_SIZE\n",
    "                train_label_error_rate += session.run(label_error_rate, feed_dict=feed) * BATCH_SIZE\n",
    "\n",
    "                # Write logs at every iteration.\n",
    "                summary_writer.add_summary(summary, current_epoch * num_batches_per_epoch + step)\n",
    "            print(\"Validating the epoch\",end=\"\\r\")\n",
    "            train_cost /= train_num\n",
    "            train_label_error_rate /= train_num\n",
    "            validation_feed = {inputs_placeholder: validation_inputs,\n",
    "                               labels_placeholder: validation_labels,\n",
    "                               sequence_length_placeholder: validation_sequence_lengths}\n",
    "\n",
    "            validation_cost, validation_label_error_rate = session.run([cost, label_error_rate],\n",
    "                                                                       feed_dict=validation_feed)\n",
    "            validation_cost /= validation_num\n",
    "            validation_label_error_rate /= validation_num\n",
    "            print(\"Finished validation.\",\"\\n\",\"Accuracy: \",str(1-validation_label_error_rate),\" Cost:\",validation_cost )\n",
    "            \n",
    "            # Output intermediate step information.\n",
    "            logging.info(\"Epoch %d/%d (time: %.3f s)\",\n",
    "                         current_epoch + 1,\n",
    "                         NUM_EPOCHS,\n",
    "                         time.time() - start_time)\n",
    "            logging.info(\"Train cost: %.3f, train label error rate: %.3f\",\n",
    "                         train_cost,\n",
    "                         train_label_error_rate)\n",
    "            logging.info(\"Validation cost: %.3f, validation label error rate: %.3f\",\n",
    "                         validation_cost,\n",
    "                         validation_label_error_rate)\n",
    "        print(\"Finished Training!\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    config = tf.ConfigProto()\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        #print(\"starting graph\")\n",
    "        logging.debug(\"Starting new TensorFlow graph.\")\n",
    "        inputs_placeholder = tf.placeholder(tf.float32, [None, H, W, CH])\n",
    "\n",
    "        # SparseTensor placeholder required by ctc_loss op.\n",
    "        labels_placeholder = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "        # 1d array of size [batch_size].\n",
    "        sequence_length_placeholder = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        # Defining the cell.\n",
    "        #def lstm_cell():\n",
    "        #    return tf.contrib.rnn.LSTMCell(NUM_HIDDEN, state_is_tuple=True)\n",
    "\n",
    "        # Stacking rnn cells.\n",
    "        #stack = tf.contrib.rnn.MultiRNNCell(\n",
    "        #    [lstm_cell() for _ in range(NUM_LAYERS)], state_is_tuple=True)\n",
    "\n",
    "        # Creates a recurrent neural network.\n",
    "        #outputs, _ = tf.nn.dynamic_rnn(stack, inputs_placeholder, sequence_length_placeholder, dtype=tf.float32)\n",
    "\n",
    "        shape = tf.shape(inputs_placeholder)\n",
    "        batch_size, max_time_steps = shape[0], shape[1]\n",
    "\n",
    "        # Reshaping to apply the same weights over the time steps.\n",
    "        #outputs = tf.reshape(outputs, [-1, NUM_HIDDEN])\n",
    "        rnn_out, _ = multi_dimensional_rnn_while_loop(rnn_size=NUM_HIDDEN, input_data=inputs_placeholder, sh=[WIND_H, WIND_W])\n",
    "        \"\"\"weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_CLASSES], stddev=0.1),\n",
    "                              name='weights')\n",
    "        bias = tf.Variable(tf.constant(0., shape=[NUM_CLASSES]),\n",
    "                           name='bias')\n",
    "\n",
    "        # Doing the affine projection.\n",
    "        print(outputs.shape, weights.shape)\n",
    "        logits = tf.matmul(outputs, weights) + bias\"\"\"\n",
    "        model_out = slim.fully_connected(inputs=rnn_out,\n",
    "                                num_outputs=66,\n",
    "                                activation_fn=None)\n",
    "        print(model_out.shape)\n",
    "        logits = tf.reshape(model_out,[batch_size, -1, NUM_CLASSES])\n",
    "        #print(logits.shape)\n",
    "        #print(rnn_out.shape)\n",
    "        # Reshaping back to the original shape.\n",
    "        #logits = tf.reshape(logits, [batch_size, -1, NUM_CLASSES])\n",
    "\n",
    "        # Time is major.\n",
    "        logits = tf.transpose(logits, (1, 0, 2))\n",
    "        #print(\"defining loss\")\n",
    "        with tf.name_scope('loss'):\n",
    "            loss = tf.nn.ctc_loss(labels_placeholder, logits, sequence_length_placeholder)\n",
    "            cost = tf.reduce_mean(loss)\n",
    "            tf.summary.scalar(\"loss\", cost)\n",
    "        #print(\"defining optimizer\")\n",
    "        optimizer = tf.train.MomentumOptimizer(INITIAL_LEARNING_RATE, 0.9).minimize(cost)\n",
    "\n",
    "        # CTC decoder.\n",
    "        #print(\"decoder and label error rate\")\n",
    "        decoded, neg_sum_logits = tf.nn.ctc_greedy_decoder(logits, sequence_length_placeholder)\n",
    "\n",
    "        label_error_rate = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                                           labels_placeholder))\n",
    "    #print(\"starting session\")\n",
    "    with tf.Session(config=config, graph=graph) as session:\n",
    "        logging.debug(\"Starting TensorFlow session.\")\n",
    "\n",
    "        # Saver op to save and restore all the variables.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Merge all the summaries and write them out.\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "\n",
    "        # Initializing summary writer for TensorBoard.\n",
    "        summary_writer = tf.summary.FileWriter(SUMMARY_PATH, tf.get_default_graph())\n",
    "\n",
    "        # Initialize the weights and biases.\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        print(\"Testing...\")\n",
    "        test_feed = {inputs_placeholder: test_inputs,\n",
    "                     sequence_length_placeholder: test_sequence_lengths}\n",
    "        # Decoding.\n",
    "        decoded_outputs = session.run(decoded[0], feed_dict=test_feed)\n",
    "        dense_decoded = tf.sparse_tensor_to_dense(decoded_outputs, default_value=-1).eval(session=session)\n",
    "        test_num = 211#x_test.shape[0]\n",
    "\n",
    "        for i, sequence in enumerate(dense_decoded):\n",
    "            sequence = [s for s in sequence if s != -1]\n",
    "            decoded_text = sequence_decoder(sequence)\n",
    "\n",
    "            logging.info(\"Sequence %d/%d\", i + 1, test_num)\n",
    "            logging.info(\"Original:\\n%s\", test_texts[i])\n",
    "            logging.info(\"Decoded:\\n%s\", decoded_text)\n",
    "        print(\"Saving model...\")\n",
    "        # Save model weights to disk.\n",
    "        save_path = saver.save(session, MODEL_PATH)\n",
    "        logging.info(\"Model saved in file: %s\", save_path)\n",
    "        print(\"END!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_to_plot = 10\n",
    "fig, axs = plt.subplots(figs_to_plot, figsize=(8, 1.3*figs_to_plot))\n",
    "\n",
    "for i in range(figs_to_plot):\n",
    "    n = int(random.random()*len(x_test))\n",
    "    image, actual_label = x_test[n],y_test[n]\n",
    "    image, _ = transform(image, actual_label)\n",
    "\n",
    "    image = nd.array(image)\n",
    "    image = image.as_in_context(ctx)\n",
    "    image = image.expand_dims(axis=0)\n",
    "    output = net(image)\n",
    "    predictions = output.softmax().topk(axis=2).asnumpy()\n",
    "    decoded_prediction_text = decode(predictions)[0].replace(\"&quot\", '\\\"').replace(\"&amp\", \"&\").replace('\";', '\\\"')\n",
    "    axs[i].imshow(image.asnumpy().squeeze(), cmap='Greys_r')\n",
    "    axs[i].set_title(\"[Label]: {}\\n[Pred]:  {}\".format(actual_label[0].replace(\"&quot\", '\\\"').replace(\"&amp\", \"&\").replace('\";', '\\\"'), decoded_prediction_text),\n",
    "                    fontdict={\"horizontalalignment\":\"left\", \"family\":\"monospace\"}, x=0)\n",
    "    axs[i].tick_params(axis='both',       \n",
    "                       which='both',      \n",
    "                       bottom=False,      \n",
    "                       top=False,         \n",
    "                       left=False,\n",
    "                       right=False,\n",
    "                       labelleft=False,\n",
    "                       labelbottom=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
